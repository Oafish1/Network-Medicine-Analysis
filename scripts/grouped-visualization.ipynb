{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd \"Compound GRN ENC Analysis/scripts\"\n",
    "%matplotlib agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "# Params\n",
    "DATA_FOLDER = os.path.join(os.path.abspath(''), '../../data')\n",
    "RESULTS_FOLDER = os.path.join(os.path.abspath(''), '../results')\n",
    "PLOTS_FOLDER = os.path.join(os.path.abspath(''), '../plots')\n",
    "\n",
    "# Style\n",
    "sns.set_theme(context='talk', style='white', palette='Accent')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['font.family'] = 'Helvetica'  # NOTE: Make sure to download Helvetica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Pull all results at beginning, then just make copies\n",
    "# Fix processing for subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cohort : Disease : Delimiter\n",
    "CMC: SCZ : tsv\n",
    "UCLA_ASD: ASD : csv\n",
    "Urban_DLPFC: BPD, SCZ : tsv\n",
    "Subclass: ASD, BPD, SCZ : csv\n",
    "\"\"\"\n",
    "data_sources = (\n",
    "    ('CMC', 'SCZ', '\\t'),\n",
    "    ('UCLA_ASD', 'ASD', ','),\n",
    "    ('Urban_DLPFC', 'BPD', '\\t'),\n",
    "    # ('Urban_DLPFC', 'SCZ', '\\t'),  # Removed for low sample size\n",
    "    ('Subclass', 'ASD', ','),\n",
    "    ('Subclass', 'BPD', ','),\n",
    "    ('Subclass', 'SCZ', ','),\n",
    "    # ('Coregulation', 'ASD', ','),\n",
    "    # ('Coregulation', 'BPD', ','),\n",
    "    # ('Coregulation', 'SCZ', ','),\n",
    ")\n",
    "modules = [None, 1, 2]\n",
    "use_ctl = True  # Not really needed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AD, BPD, and SCZ labels\n",
    "gene_dir = os.path.join(DATA_FOLDER, 'new_labels')\n",
    "gene_fnames = [fname for fname in os.listdir(gene_dir) if fname.endswith('.txt')]\n",
    "gene_lists = {'.'.join(fname.split('.')[:-1]): np.loadtxt(os.path.join(gene_dir, fname), dtype=str) for fname in gene_fnames}\n",
    "gene_lists['BPD'] = gene_lists.pop('BD')\n",
    "\n",
    "# Get ASD labels\n",
    "sfari = pd.read_csv(os.path.join(DATA_FOLDER, 'sfari/SFARI-Gene_genes_01-16-2024release_03-21-2024export.csv'))\n",
    "gene_score_threshold = -1\n",
    "sfari = sfari.loc[sfari['gene-score'] > gene_score_threshold]  # Threshold by score\n",
    "gene_lists['ASD'] = sfari['gene-symbol'].to_numpy()\n",
    "\n",
    "# Get module genes\n",
    "def get_module_genes(group, disease, ct, use_modules=None):\n",
    "    gene_annotations = pd.read_csv(os.path.join(DATA_FOLDER, 'modules', get_modules_fname(use_modules=use_modules), f'{ct}_{group}_{disease}.txt'), index_col=False, delimiter=',')\n",
    "    positive_genes = gene_annotations.loc[gene_annotations['label']=='positive', 'gene'].to_list()\n",
    "    negative_genes = gene_annotations.loc[gene_annotations['label']=='negative', 'gene'].to_list()\n",
    "    return positive_genes, negative_genes\n",
    "\n",
    "# Get files for contrast\n",
    "def get_grn_fnames(group, disease, use_ctl=True):\n",
    "    # Calculate directories\n",
    "    base_dir = os.path.join(DATA_FOLDER, 'merged_GRNs_v2', group)\n",
    "    disease_folder = os.path.join(base_dir, disease)\n",
    "    if use_ctl:\n",
    "        control_folder = os.path.join(base_dir, 'ctrl')\n",
    "        grn_fnames = np.sort(list(set(os.listdir(disease_folder)).intersection(set(os.listdir(control_folder)))))\n",
    "    else: grn_fnames = np.sort(os.listdir(disease_folder)) \n",
    "\n",
    "    # Return\n",
    "    ret = ()\n",
    "    ret += (base_dir, disease_folder)\n",
    "    if use_ctl: ret += (control_folder,)\n",
    "    ret += (grn_fnames,)\n",
    "    # base_dir, disease_folder, control_folder, grn_fnames\n",
    "    return ret\n",
    "\n",
    "# Get fname suffix\n",
    "def get_modules_fname(use_modules, **kwargs): return f'model{use_modules}' if use_modules is not None else ''\n",
    "def get_fname_suffix(**kwargs):\n",
    "    suffixes = [get_modules_fname(**kwargs)]\n",
    "    suffixes = [s for s in suffixes if len(s) > 0]\n",
    "    if len(suffixes) == 0: return ''\n",
    "    return f'_{\"_\".join(suffixes)}'\n",
    "\n",
    "# Get cell-type based on fname\n",
    "get_cell_type = lambda fname: '_'.join(fname.split('_')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass major pairing\n",
    "inhibitory = ['Lamp5', 'Pvalb', 'Sncg', 'Sst','Sst.Chodl', 'Lamp5.Lhx6', 'Vip','Pax6','Chandelier']\n",
    "excitatory = ['L2.3.IT', 'L4.IT', 'L5.IT', 'L5.ET', 'L5.6.NP','L6b','L6.IT','L6.CT','L6.IT.Car3']\n",
    "ct_conversion = {**{ct: 'inhibitory' for ct in inhibitory}, **{ct: 'excitatory' for ct in excitatory}}\n",
    "# Disease pairings\n",
    "group_conversion = {'ASD': 'UCLA_ASD', 'BPD': 'Urban_DLPFC', 'SCZ': 'CMC'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine cell types\n",
    "# group, disease, delimiter = data_sources[0]\n",
    "# fname = os.path.join(RESULTS_FOLDER, f'{group}_{disease}_performance{get_fname_suffix(use_modules=None)}.csv')\n",
    "# df = pd.read_csv(fname, index_col=0)\n",
    "# major_ct = df['Cell Type'].unique()\n",
    "major_ct = np.array(['astro', 'endo', 'excitatory', 'inhibitory', 'micro', 'oligo', 'opc', 'vlmc'])\n",
    "# group, disease, delimiter = data_sources[-1]\n",
    "# fname = os.path.join(RESULTS_FOLDER, f'{group}_{disease}_performance{get_fname_suffix(use_modules=None)}.csv')\n",
    "# df = pd.read_csv(fname, index_col=0)\n",
    "# minor_ct = df['Cell Type'].unique()\n",
    "minor_ct = np.array(['Chandelier', 'L2.3.IT', 'L4.IT', 'L5.6.NP', 'L5.ET', 'L5.IT', 'L6.CT', 'L6.IT.Car3', 'L6.IT', 'L6b', 'Lamp5.Lhx6', 'Lamp5', 'Pax6', 'Pvalb', 'Sncg', 'Sst', 'Vip'])\n",
    "\n",
    "# Colors\n",
    "major_palette = sns.color_palette('Dark2', as_cmap=True)\n",
    "minor_palette = sns.color_palette('magma', as_cmap=True)\n",
    "major_colors = {ct: major_palette((i+1) / (len(major_ct) + 1)) for i, ct in enumerate(major_ct)}\n",
    "minor_colors = {ct: minor_palette((i+1) / (len(minor_ct) + 1)) for i, ct in enumerate(minor_ct)}\n",
    "merged_colors = major_colors | minor_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Major and legends\n",
    "for name, colors in zip(('major', 'minor'), (major_colors, minor_colors)):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.spines.top.set_visible(False)  # Avoid line through legend if too long\n",
    "    handles = [ax.plot([], [], color=c, marker='s', ls='none')[0] for c in colors.values()]\n",
    "    labels = list(colors.keys())\n",
    "    legend = plt.legend(handles, labels, loc=3, frameon=False)\n",
    "    ax.axis('off')\n",
    "    bbox = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "    fname = f'legend_{name}.pdf'\n",
    "    fig.savefig(os.path.join(PLOTS_FOLDER, fname), bbox_inches=bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Params\n",
    "# horizontal = False\n",
    "\n",
    "# for use_modules in modules:\n",
    "#     # Get performance df\n",
    "#     performance = pd.DataFrame()\n",
    "#     for source in data_sources:\n",
    "#         group, disease, delimiter = source\n",
    "\n",
    "#         # Load performance\n",
    "#         fname = os.path.join(RESULTS_FOLDER, f'{group}_{disease}_performance{get_fname_suffix(use_modules=use_modules)}.csv')\n",
    "#         try: df = pd.read_csv(fname, index_col=0)\n",
    "#         except: continue\n",
    "#         df['Group'] = group\n",
    "#         df['Disease'] = disease\n",
    "\n",
    "#         # Get baselines\n",
    "#         def get_baseline(ct):\n",
    "#             df_temp = pd.read_csv(os.path.join(RESULTS_FOLDER, f'{group}_{disease}_{ct}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'), index_col=0)\n",
    "#             num_neg = (df_temp['label'] == 0).sum()\n",
    "#             num_pos = (df_temp['label'] == 1).sum()\n",
    "#             baseline = num_pos / (num_pos + num_neg)\n",
    "\n",
    "#             return baseline\n",
    "#         df['Baseline AUPRC'] = df['Cell Type'].map(get_baseline)\n",
    "\n",
    "#         # Concatenate\n",
    "#         performance = pd.concat((performance, df), axis=0)\n",
    "\n",
    "#     # Take means\n",
    "#     performance = performance.drop(columns='Fold').groupby(['Group', 'Disease', 'Cell Type']).mean().reset_index()\n",
    "\n",
    "#     # Apply formatting\n",
    "#     # performance['Dataset'] = performance.apply(lambda r: f'{r[\"Group\"]} ({r[\"Disease\"]})', axis=1)  # Include group name\n",
    "#     performance['Dataset'] = performance.apply(lambda r: f'{r[\"Disease\"]}', axis=1)  # Exclude group name\n",
    "\n",
    "#     # Compute fold changes\n",
    "#     for stat in ('AUPRC', 'Validation AUPRC'):\n",
    "#         performance[f'{stat} Fold Change'] = performance[stat] / performance['Baseline AUPRC']\n",
    "\n",
    "#     # Plot\n",
    "#     fnames = [\n",
    "#         f'Performance_Main{get_fname_suffix(use_modules=use_modules)}.pdf',\n",
    "#         f'Performance_Subclass{get_fname_suffix(use_modules=use_modules)}.pdf',\n",
    "#     ]\n",
    "#     plot_cell_types_lists = [\n",
    "#         performance.loc[performance['Group'] != 'Subclass', 'Cell Type'].unique().tolist(),\n",
    "#         performance.loc[performance['Group'] == 'Subclass', 'Cell Type'].unique().tolist(),\n",
    "#     ]\n",
    "#     scale = [\n",
    "#         1,\n",
    "#         2\n",
    "#     ]\n",
    "#     for fname, plot_cell_types, sc in zip(fnames, plot_cell_types_lists, scale):\n",
    "#         # Check for data\n",
    "#         if len(plot_cell_types) == 0: break\n",
    "\n",
    "#         # Filter to cell types\n",
    "#         performance_filtered = performance.loc[performance['Cell Type'].isin(plot_cell_types)]\n",
    "\n",
    "#         # Format as heatmap\n",
    "#         order_dataset = performance_filtered[['Group', 'Disease', 'Dataset']].groupby(['Group', 'Disease', 'Dataset']).count().reset_index().sort_values(['Disease', 'Group'])['Dataset'].to_list()\n",
    "#         order_cell = performance_filtered.sort_values('Cell Type')['Cell Type'].unique()\n",
    "#         if horizontal: order_dataset = order_dataset[::-1]\n",
    "#         else: order_cell = order_cell[::-1]\n",
    "#         heatmap_data = performance_filtered.pivot(index='Dataset', columns='Cell Type', values='AUPRC Fold Change').loc[order_dataset, order_cell]\n",
    "#         heatmap_data_val = performance_filtered.pivot(index='Dataset', columns='Cell Type', values='Validation AUPRC Fold Change').loc[order_dataset, order_cell]\n",
    "#         if not horizontal:\n",
    "#             heatmap_data = heatmap_data.transpose()\n",
    "#             heatmap_data_val = heatmap_data_val.transpose()\n",
    "\n",
    "#         # Plot\n",
    "#         figsize = heatmap_data.shape[::-1] if horizontal else [sc*s for s in heatmap_data.shape]\n",
    "#         fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "#         # Define vars\n",
    "#         xlabels = heatmap_data.columns.to_list()\n",
    "#         ylabels = heatmap_data.index.to_list()\n",
    "#         m, n = heatmap_data.shape[1], heatmap_data.shape[0]\n",
    "#         X, Y = np.meshgrid(np.arange(m), np.arange(n))\n",
    "#         S = heatmap_data.to_numpy()\n",
    "#         T = heatmap_data_val.to_numpy()\n",
    "\n",
    "#         # Squares are training, circles are validation\n",
    "#         maxval = 2 if not use_modules else 20\n",
    "#         norm = matplotlib.colors.TwoSlopeNorm(vmin=0, vcenter=1, vmax=maxval)\n",
    "#         patches = [plt.Rectangle((j-.5, i-.5), 1, 1) for j, i in zip(X.flat, Y.flat)]\n",
    "#         col = PatchCollection(patches, array=S.flatten(), linewidth=0, clim=[0, maxval], norm=norm, cmap='RdBu')\n",
    "#         ax.add_collection(col)\n",
    "#         patches = [plt.Circle((j, i), .4) for j, i in zip(X.flat, Y.flat)]\n",
    "#         col = PatchCollection(patches, array=T.flatten(), linewidth=0, clim=[0, maxval], norm=norm, cmap='RdBu')\n",
    "#         ax.add_collection(col)\n",
    "#         from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "#         divider = make_axes_locatable(ax)\n",
    "#         cax = divider.append_axes('top', size=\"5%\", pad=.5)\n",
    "#         cbar = fig.colorbar(col, orientation='horizontal', cax=cax)\n",
    "#         cbar.ax.set_xlabel('AUPRC Fold Change', fontsize='small')\n",
    "#         cbar.ax.xaxis.set_label_position('top') \n",
    "#         cbar.ax.set_xticks([0, 1, maxval])  # Add 1 as an xtick\n",
    "\n",
    "#         ax.set(\n",
    "#             xticks=np.arange(m),\n",
    "#             yticks=np.arange(n),\n",
    "#             xticklabels=xlabels,\n",
    "#             yticklabels=ylabels,\n",
    "#         )\n",
    "#         ax.set_xticks(np.arange(m+1)-.5, minor=True)\n",
    "#         ax.set_yticks(np.arange(n+1)-.5, minor=True)\n",
    "#         ax.tick_params(axis='x', labelrotation=90)\n",
    "#         ax.grid(which='minor')\n",
    "#         ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "#         fig.savefig(os.path.join(PLOTS_FOLDER, fname), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame()\n",
    "for source, use_modules in product(data_sources, modules):\n",
    "    group, disease, delimiter = source\n",
    "\n",
    "    # Skip non-models\n",
    "    if not use_modules: continue\n",
    "\n",
    "    # Load performance\n",
    "    fname = os.path.join(RESULTS_FOLDER, f'{group}_{disease}_performance{get_fname_suffix(use_modules=use_modules)}.csv')\n",
    "    try: df = pd.read_csv(fname, index_col=0)\n",
    "    except: continue\n",
    "    df['Group'] = group\n",
    "    df['Disease'] = disease\n",
    "    df['Model'] = f'Model {use_modules}'\n",
    "\n",
    "    # Get baselines\n",
    "    def get_baseline(ct):\n",
    "        df_temp = pd.read_csv(os.path.join(RESULTS_FOLDER, f'{group}_{disease}_{ct}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'), index_col=0)\n",
    "        num_neg = (df_temp['label'] == 0).sum()\n",
    "        num_pos = (df_temp['label'] == 1).sum()\n",
    "        baseline = num_pos / (num_pos + num_neg)\n",
    "\n",
    "        return baseline\n",
    "    df['Baseline AUPRC'] = df['Cell Type'].map(get_baseline)\n",
    "\n",
    "    # Concatenate\n",
    "    performance = pd.concat((performance, df), axis=0)\n",
    "\n",
    "# Apply formatting\n",
    "# performance['Dataset'] = performance.apply(lambda r: f'{r[\"Group\"]} ({r[\"Disease\"]})', axis=1)  # Include group name\n",
    "performance['Dataset'] = performance.apply(lambda r: f'{r[\"Group\"]} - {r[\"Disease\"]} - {r[\"Cell Type\"]}', axis=1)  # Exclude group name\n",
    "\n",
    "# Aggregate values\n",
    "performance['AUPRC Fold'] = performance['Validation AUPRC'] / performance['Baseline AUPRC']\n",
    "\n",
    "# Sort df\n",
    "performance['Subclass'] = performance['Group'] == 'Subclass'\n",
    "performance = performance.sort_values(['Disease', 'Subclass', 'Group']).drop(columns='Subclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ypos = -.1  # Position of the major disease labels\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30, 4))\n",
    "sns.barplot(data=performance, x='Dataset', y='AUPRC Fold', hue='Model', ax=ax)\n",
    "\n",
    "# Formatting\n",
    "sns.despine()\n",
    "ax.set_xlabel(None)\n",
    "\n",
    "# Set xticklabels\n",
    "original = []\n",
    "diseases = []\n",
    "groups = []\n",
    "cell_types = []\n",
    "for l in ax.get_xticklabels():\n",
    "    split = l.get_text().split(' - ')\n",
    "    original.append(l.get_text())\n",
    "    groups.append(split[0])\n",
    "    diseases.append(split[1])\n",
    "    cell_types.append(split[2])\n",
    "ax.set_xticklabels([], rotation=90)  # cell_types\n",
    "\n",
    "# Set limits\n",
    "ax.set_xlim([-.5, len(cell_types)-.5])\n",
    "\n",
    "# Recolor\n",
    "for bars, hatch in zip(ax.containers, [None, '///']):\n",
    "    for bar, ct in zip(bars, cell_types):\n",
    "        bar.set_facecolor(merged_colors[ct])\n",
    "        bar.set_hatch(hatch)\n",
    "\n",
    "# Remove legend title\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles, labels=labels)\n",
    "\n",
    "# Draw baselines\n",
    "## Non-scaled\n",
    "# for x, dataset in enumerate(original):\n",
    "#     baseline = performance.loc[performance['Dataset'] == dataset, 'Baseline AUPRC'].mean()\n",
    "## Scaled\n",
    "ax.axhline(y=1, linewidth=.5, linestyle='dashed', color='black')\n",
    "\n",
    "# Draw group labels\n",
    "trans = matplotlib.transforms.blended_transform_factory(ax.transData, ax.transAxes)\n",
    "lidx = 0\n",
    "for ridx in range(len(diseases)):\n",
    "    if (ridx == len(diseases) - 1) or (diseases[ridx+1] != diseases[ridx]):\n",
    "        # Draw label\n",
    "        xpos = (lidx + ridx) / 2\n",
    "        label = f'{diseases[ridx]}'\n",
    "        # TODO: Maybe separate subclass and non-subclass?\n",
    "        # if groups[ridx] == 'Subclass': label += ' Subclass'\n",
    "        ax.text(xpos, ypos, label, ha='center', va='bottom', fontsize='medium', transform=trans)\n",
    "\n",
    "        # Draw lines\n",
    "        it = [ridx+.5]\n",
    "        if lidx == 0: it += [lidx-.5]\n",
    "        for xpos in it:\n",
    "            ax.arrow(\n",
    "                xpos, 0, 0, ypos,\n",
    "                width=.01,\n",
    "                head_width=0,\n",
    "                transform=trans,\n",
    "                color='black',\n",
    "                clip_on=False)\n",
    "            pass\n",
    "\n",
    "        # Iterate\n",
    "        lidx = ridx + 1\n",
    "\n",
    "# Save\n",
    "fname = f'Performance.pdf'\n",
    "fig.savefig(os.path.join(PLOTS_FOLDER, fname), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19217/3275761450.py:16: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axs = plt.subplots(len(grn_fnames), len(ranges), figsize=figsize, width_ratios=width_ratios, sharex='col', sharey='row', gridspec_kw={'hspace': -.5, 'wspace': .1})\n"
     ]
    }
   ],
   "source": [
    "for source, use_modules in product(data_sources, modules):\n",
    "    group, disease, _ = source\n",
    "    grn_fnames = get_grn_fnames(group, disease, use_ctl=use_ctl)[-1]\n",
    "\n",
    "    # Plot\n",
    "    ranges = [(None, None)]  # [(0, .55), (.85, 1)]\n",
    "    width_ratios = [\n",
    "        (\n",
    "            (rg[1] - rg[0])\n",
    "            if (rg[0] is not None) and (rg[1] is not None)\n",
    "            else 1\n",
    "        )\n",
    "        for rg in ranges\n",
    "    ]\n",
    "    figsize = (10, 10)  # (10, len(grn_fnames) // 2)\n",
    "    fig, axs = plt.subplots(len(grn_fnames), len(ranges), figsize=figsize, width_ratios=width_ratios, sharex='col', sharey='row', gridspec_kw={'hspace': -.5, 'wspace': .1})\n",
    "    axs = axs.reshape(-1, 1)\n",
    "    fig.suptitle(f'{group} ({disease})')\n",
    "\n",
    "    content = False\n",
    "    for i, fname in enumerate(grn_fnames):\n",
    "        cell_type = get_cell_type(fname)\n",
    "        result_fname = f'{group}_{disease}_{cell_type}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'\n",
    "        try: result = pd.read_csv(os.path.join(RESULTS_FOLDER, result_fname), index_col=0)\n",
    "        except: continue\n",
    "        content = True\n",
    "\n",
    "        # Scale score from 0-1 PER CELL TYPE\n",
    "        result['mean'] /= result['mean'].max()  # Do we include this?\n",
    "\n",
    "        for j, (ax, rgs) in enumerate(zip(axs[i], ranges)):\n",
    "            # KDS\n",
    "            sns.kdeplot(result['mean'], lw=0, color='white', ax=ax)\n",
    "            x, y = ax.get_lines()[0].get_xydata().T\n",
    "\n",
    "            # Stylizing and coloration\n",
    "            ax.set_xlabel(None)\n",
    "            ax.set_ylabel(None)\n",
    "            ax.set_yticklabels([])\n",
    "            # Color\n",
    "            # color_val = (i+2) / (len(grn_fnames)+3)  # Padded\n",
    "            # # color_val = i / len(grn_fnames)  # Unpadded\n",
    "            # color = matplotlib.colormaps['Blues'](color_val)\n",
    "            color = merged_colors[cell_type]\n",
    "            ax.fill_between(x, 0, y, color=color)\n",
    "\n",
    "            patches = []\n",
    "            width = 3e-3  # if group != 'Subclass' else 3e-6\n",
    "            alpha = .05\n",
    "            # alpha = 2 / (result.loc[result['label'] != -1, 'label']).sum()\n",
    "            # alpha = (result.loc[result['label'] != -1, 'label']).sum() / result['label'].count()\n",
    "            for r in result.loc[result['label'] == 1].iterrows():\n",
    "                score = (r[1]['mean'])\n",
    "\n",
    "                # Fill\n",
    "                # NOTE: Could also compute KDE of positive labels and use a gradient\n",
    "                xrange = np.linspace(max(0, score-width), min(1, score+width), 10)\n",
    "                ytop = np.interp(xrange, x, y)\n",
    "                ax.fill_between(xrange, 0, ytop, color='red', alpha=alpha)\n",
    "                \n",
    "                # Patches\n",
    "                # height = np.interp(score, x, y)\n",
    "                # width = .1 / x.shape[0]\n",
    "                # arrow = plt.Rectangle((score, -width/2), width, height)\n",
    "                # patches.append(arrow)\n",
    "            # col = PatchCollection(patches, linewidth=0, color='salmon', alpha=.1)\n",
    "            # ax.add_collection(col)\n",
    "\n",
    "            # Formatting\n",
    "            ax.spines.left.set_visible(False)\n",
    "            ax.spines.right.set_visible(False)\n",
    "            ax.spines.top.set_visible(False)\n",
    "            ax.spines.bottom.set_visible(False)\n",
    "            # if i != len(grn_fnames) - 1: ax.spines.bottom.set_visible(False)\n",
    "            left, right = rgs\n",
    "            if left is not None: ax.set_xlim(left=left)\n",
    "            if right is not None: ax.set_xlim(right=right)\n",
    "            ax.patch.set_alpha(0)  # Make background transparent\n",
    "            if j == 0: ax.text(-.02, 0, cell_type, fontsize='small', ha='right', va='bottom', transform=ax.transAxes)  # Add y label\n",
    "\n",
    "            # Plot split line\n",
    "            if i == len(grn_fnames) - 1:\n",
    "                # Create marker\n",
    "                kwargs = dict(marker=[(-.5, -1), (.5, 1)], markersize=12, linestyle='none', color='k', mec='k', mew=2, clip_on=False)\n",
    "\n",
    "                # Plot markers\n",
    "                if j > 0: ax.plot([0], [0], transform=ax.transAxes, **kwargs)\n",
    "                if j < len(ranges) - 1: ax.plot([1], [0], transform=ax.transAxes, **kwargs)\n",
    "                \n",
    "            # Set ticks to only between 0 and 1, only set in here for broken purposes\n",
    "            xticks = [x for x in ax.get_xticks() if x >= -.01 and x <= 1.01]\n",
    "            ax.set_xticks(xticks)\n",
    "\n",
    "    # Skip if no data\n",
    "    if not content: continue\n",
    "\n",
    "    # Final formatting\n",
    "    fig.text(.5, 0, 'Gene Relevance Score', fontsize='medium', ha='center', va='center')\n",
    "\n",
    "    # Save\n",
    "    fname = f'Distribution_{group}_{disease}{get_fname_suffix(use_modules=use_modules)}.pdf'\n",
    "    fig.savefig(os.path.join(PLOTS_FOLDER, fname), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBB Drug Target Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load drugs and gene lists\n",
    "drugs = pd.read_csv(os.path.join(DATA_FOLDER, 'pharmacologically_active.csv')).rename(columns={'Drug IDs': 'Drug ID'})\n",
    "drugs = drugs[['Gene Name', 'Drug ID', 'Species']]\n",
    "drugs['Drug ID'] = drugs['Drug ID'].apply(lambda s: s.split('; '))\n",
    "drugs = drugs.explode('Drug ID')\n",
    "\n",
    "# Add BBB predictions\n",
    "bbb = pd.read_csv(os.path.join(DATA_FOLDER, 'BBB_plus_dbIDS.csv'), index_col=0)\n",
    "drugs['BBB'] = drugs['Drug ID'].map(lambda x: x in list(bbb['ID']))\n",
    "\n",
    "# Get BBB drug targets\n",
    "bbb_drug_targets = drugs.loc[drugs['BBB'], 'Gene Name'].unique()  # Figure out why 'G', 'L', etc. in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all results (Taken from model-ensemble)\n",
    "results = pd.DataFrame()\n",
    "for source in data_sources:\n",
    "    group, disease, _ = source\n",
    "    grn_fnames = get_grn_fnames(group, disease, use_ctl=use_ctl)[-1]\n",
    "\n",
    "    for fname, use_modules in product(grn_fnames, modules):\n",
    "        # Load prioritized genes\n",
    "        cell_type = get_cell_type(fname)\n",
    "        result_fname = f'{group}_{disease}_{cell_type}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'\n",
    "        try: result = pd.read_csv(os.path.join(RESULTS_FOLDER, result_fname), index_col=0).reset_index()\n",
    "        except: continue\n",
    "\n",
    "        # Tag df\n",
    "        renames = {'label': 'Label', 'mean': 'Mean', 'std': 'STD', 'gene': 'Gene'}\n",
    "        result = result.rename(columns=renames)[renames.values()]\n",
    "        result['Group'] = group\n",
    "        result['Disease'] = disease\n",
    "        result['Cell Type'] = cell_type\n",
    "        result['Model'] = use_modules\n",
    "\n",
    "        # Append\n",
    "        results = pd.concat((results, result), axis=0)\n",
    "    \n",
    "# Format and decide targets\n",
    "group_cols = ['Group', 'Disease', 'Cell Type', 'Model']\n",
    "results['BBB Count'] = results['Gene'].isin(bbb_drug_targets)\n",
    "results['Model'] = results['Model'].fillna('None')  # Necessary for proper groupby behavior\n",
    "results = results.set_index(group_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "quantile = .9  # BBB targets in the top 10%\n",
    "\n",
    "# Filter to desired quantile\n",
    "thresholds = results.groupby(group_cols).quantile(quantile, numeric_only=True)[['Mean']]\n",
    "results['_mask'] = None\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    for idx in thresholds.index:\n",
    "        results.loc[idx, '_mask'] = results.loc[idx, 'Mean'] > thresholds.loc[idx, 'Mean']\n",
    "assert results['_mask'].isna().sum() == 0, 'Not all values checked'\n",
    "results = results.loc[results['_mask']].drop(columns='_mask')\n",
    "\n",
    "# Compute counts of BBB targets and pivot separate by model\n",
    "bbb_counts = results.groupby(group_cols)[['BBB Count']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (fname_suffix, df) in zip(\n",
    "    (\n",
    "        'major',\n",
    "        'minor',\n",
    "    ),\n",
    "    (\n",
    "        bbb_counts.loc[bbb_counts.index.get_level_values('Group') != 'Subclass'],  # Non-subclass\n",
    "        bbb_counts.loc[bbb_counts.index.get_level_values('Group') == 'Subclass'],  # Subclass\n",
    "    ),\n",
    "):\n",
    "    # Check if df is empty\n",
    "    if df.shape[0] == 0:\n",
    "        print(f'Input DataFrame for {fname_suffix} is empty, skipping.')\n",
    "\n",
    "    # Generate heatmaps\n",
    "    heatmap_1 = df.loc[df.index.get_level_values('Model') == 1].reset_index().pivot(index='Cell Type', columns='Disease', values='BBB Count').iloc[::-1]\n",
    "    heatmap_2 = df.loc[df.index.get_level_values('Model') == 2].reset_index().pivot(index='Cell Type', columns='Disease', values='BBB Count').iloc[::-1]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    # Define vars\n",
    "    xlabels = heatmap_1.columns.to_list()\n",
    "    ylabels = heatmap_1.index.to_list()\n",
    "    m, n = heatmap_1.shape[1], heatmap_1.shape[0]\n",
    "    X, Y = np.meshgrid(np.arange(m), np.arange(n))\n",
    "    S = heatmap_1.to_numpy()\n",
    "    T = heatmap_2.to_numpy()\n",
    "\n",
    "    # Make monochrome cmap\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    cdict = {\n",
    "        'red': [3*[0.], 3*[1.]],\n",
    "        'green': [3*[0.], 3*[1.]],\n",
    "        'blue': [3*[0.], 3*[1.]],\n",
    "    }\n",
    "    cmap = LinearSegmentedColormap('Monochrome', segmentdata=cdict, N=256).reversed()\n",
    "\n",
    "    # Top left is model 1, bottom right is model 2\n",
    "    maxval = 20\n",
    "    patches = [plt.Polygon([[j-.5, i-.5], [j+.5, i+.5], [j-.5, i+.5]]) for j, i in zip(X.flat, Y.flat)]\n",
    "    col = PatchCollection(patches, array=S.flatten(), linewidth=0, clim=[0, maxval], cmap=cmap)\n",
    "    ax.add_collection(col)\n",
    "    patches = [plt.Polygon([[j-.5, i-.5], [j+.5, i+.5], [j+.5, i-.5]]) for j, i in zip(X.flat, Y.flat)]\n",
    "    col = PatchCollection(patches, array=T.flatten(), linewidth=0, clim=[0, maxval], cmap=cmap)\n",
    "    ax.add_collection(col)\n",
    "\n",
    "    # Modify colors to match cell types\n",
    "    fig.canvas.draw()  # Needed to set facecolors originally\n",
    "    for collection in ax.collections:\n",
    "        facecolors = collection.get_facecolors()\n",
    "        for i, x, y in zip(range(facecolors.shape[0]), X.flat, Y.flat):\n",
    "            ct = ylabels[y]\n",
    "            ct_color = merged_colors[ct]\n",
    "            color = (1 - facecolors[i]) * ct_color + facecolors[i]\n",
    "            color[-1] = facecolors[i][-1]  # Don't include missing data\n",
    "            facecolors[i] = color\n",
    "        collection.set_array(None)\n",
    "        collection.set_facecolors(facecolors)\n",
    "\n",
    "    # Set ticks\n",
    "    ax.set(\n",
    "        xticks=np.arange(m),\n",
    "        yticks=np.arange(n),\n",
    "        xticklabels=xlabels,\n",
    "        yticklabels=ylabels,\n",
    "    )\n",
    "    ax.set_xticks(np.arange(m+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(n+1)-.5, minor=True)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    ax.grid(which='minor')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # Formatting\n",
    "    ax.spines.left.set_visible(False)\n",
    "    ax.spines.right.set_visible(False)\n",
    "    ax.spines.top.set_visible(False)\n",
    "    ax.spines.bottom.set_visible(False)\n",
    "\n",
    "    # Save\n",
    "    fname = f'BBB_Prevalence_{fname_suffix}.pdf'\n",
    "    fig.savefig(os.path.join(PLOTS_FOLDER, fname), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save colorbar legend\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, .5))\n",
    "cbar = fig.colorbar(col, orientation='horizontal', cax=ax)\n",
    "cbar.ax.set_xlabel('BBB Targets', fontsize='small')\n",
    "# cbar.ax.set_ylabel('a')\n",
    "# cbar.ax.xaxis.set_label_position('top')\n",
    "cbar.outline.set_visible(False)\n",
    "cbar.ax.set_xticks([])\n",
    "cbar.ax.text(-.02, .5, '0', fontsize='small', ha='right', va='center', transform=cbar.ax.transAxes)\n",
    "cbar.ax.text(1.02, .5, f'{maxval}', fontsize='small', ha='left', va='center', transform=cbar.ax.transAxes)\n",
    "bbox = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "fname = f'legend_bbb_color.pdf'\n",
    "fig.savefig(os.path.join(PLOTS_FOLDER, fname), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "# Patches\n",
    "patch = matplotlib.patches.Polygon([[-1, -1], [1, 1], [-1, 1]], color=(.9, .9, .9, 1))\n",
    "ax.add_patch(patch)\n",
    "patch = matplotlib.patches.Polygon([[-1, -1], [1, 1], [1, -1]], color=(.8, .8, .8, 1))\n",
    "ax.add_patch(patch)\n",
    "# Text\n",
    "# ax.text(0, 0, 'Center', ha='center', va='center', transform=ax.transData)\n",
    "ax.text(-.2, .2, 'Model 1', ha='center', va='center', rotation=45, transform=ax.transData)\n",
    "ax.text(.2, -.2, 'Model 2', ha='center', va='center', rotation=45, transform=ax.transData)\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "# Save\n",
    "ax.axis('off')\n",
    "fname = f'legend_bbb_shape.pdf'\n",
    "fig.savefig(os.path.join(PLOTS_FOLDER, fname), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known Medication Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load drugs and gene lists\n",
    "# drugs = pd.read_csv(os.path.join(DATA_FOLDER, 'pharmacologically_active.csv')).rename(columns={'Drug IDs': 'Drug ID'})\n",
    "# drugs = drugs[['Gene Name', 'Drug ID', 'Species']]\n",
    "# drugs['Drug ID'] = drugs['Drug ID'].apply(lambda s: s.split('; '))\n",
    "# drugs = drugs.explode('Drug ID')\n",
    "\n",
    "# # Add BBB predictions\n",
    "# bbb = pd.read_csv(os.path.join(DATA_FOLDER, 'BBB_plus_dbIDS.csv'), index_col=0)\n",
    "# drugs['BBB'] = drugs['Drug ID'].map(lambda x: x in list(bbb['ID']))\n",
    "\n",
    "# # Add scores\n",
    "# for source, use_modules in product(data_sources, modules):\n",
    "#     group, disease, _ = source\n",
    "#     grn_fnames = get_grn_fnames(group, disease, use_ctl=use_ctl)[-1]\n",
    "\n",
    "#     df_all = None\n",
    "#     for i, fname in enumerate(grn_fnames):\n",
    "#         # Load prioritization\n",
    "#         cell_type = get_cell_type(fname)\n",
    "#         result_fname = f'{group}_{disease}_{cell_type}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'\n",
    "#         try: result = pd.read_csv(os.path.join(RESULTS_FOLDER, result_fname), index_col=0)\n",
    "#         except: continue\n",
    "\n",
    "#         # Append to drugs\n",
    "#         drug_result = (\n",
    "#             drugs\n",
    "#                 .set_index('Gene Name')\n",
    "#                 .join(result[['mean', 'std']], how='inner')  # Inner join to account for missing genes\n",
    "#                 .fillna(0)\n",
    "#                 .reset_index(names='Gene')\n",
    "#         )\n",
    "\n",
    "#         # Compute drug scores\n",
    "#         # NOTE: Currently `sqrt(num_genes) * mean(means)`\n",
    "#         groupby_list = ['Drug ID', 'Species', 'BBB']\n",
    "#         df_genelist = (\n",
    "#             drug_result\n",
    "#                 .groupby(groupby_list)['Gene']\n",
    "#                 .apply(list)\n",
    "#                 .reset_index(name='Genes')\n",
    "#                 .set_index(groupby_list)\n",
    "#         )\n",
    "#         df_genelist['Num Genes'] = df_genelist['Genes'].apply(lambda l: len(l))\n",
    "#         df_means = drug_result.groupby(groupby_list)[['mean']].mean().rename(columns={'mean': 'Mean Mean'})\n",
    "#         df_stds = drug_result.groupby(groupby_list)[['std']].mean().rename(columns={'std': 'Mean STD'})\n",
    "#         df_scores = df_means\n",
    "#         df = (\n",
    "#             df_genelist\n",
    "#                 .join(df_means)\n",
    "#                 .join(df_stds)\n",
    "#         )\n",
    "#         df['Drug Relevance Score'] = df.apply(lambda r: r['Mean Mean'] * np.sqrt(r['Num Genes']), axis=1)\n",
    "#         df['Drug Relevance Score'] /= df['Drug Relevance Score'].max()  # Scale score PER CELL TYPE\n",
    "#         df = df.sort_values('Drug Relevance Score', ascending=False).reset_index()\n",
    "\n",
    "#         # Save\n",
    "#         fname = f'{group}_{disease}_{cell_type}_prioritized_drugs{get_fname_suffix(use_modules=use_modules)}.csv'\n",
    "#         df.to_csv(os.path.join(RESULTS_FOLDER, fname), index=False)\n",
    "\n",
    "#         # Append to df\n",
    "#         df['Cell Type'] = cell_type\n",
    "#         if df_all is None: df_all = df\n",
    "#         else: df_all = pd.concat((df_all, df), axis=0)\n",
    "\n",
    "#     # Skip if no data\n",
    "#     if df_all is None: continue\n",
    "\n",
    "#     # Create figure\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "#     df_filtered = df_all.loc[df_all['Species'] == 'Humans']\n",
    "#     sorted_drugs = df_filtered.groupby('Drug ID')[['Drug Relevance Score']].max().sort_values('Drug Relevance Score', ascending=False).index.to_numpy()\n",
    "\n",
    "#     # Pivot\n",
    "#     df_filtered = df_filtered.pivot(index='Cell Type', columns='Drug ID', values='Drug Relevance Score')\n",
    "\n",
    "#     # Sort\n",
    "#     df_filtered = df_filtered[sorted_drugs]\n",
    "\n",
    "#     # Plot\n",
    "#     sns.heatmap(df_filtered, vmin=0, vmax=1, cmap='Blues', ax=ax)\n",
    "#     ax.set_xlabel(None)\n",
    "#     ax.set_ylabel(None)\n",
    "\n",
    "#     # Labels\n",
    "#     to_label = {\n",
    "#         'DB00408': 'Loxapine',  # SCZ\n",
    "#         'DB04842': 'Fluspirilene',  # SCZ\n",
    "#         'DB06144': 'Sertindole',  # SCZ\n",
    "#         'DB00502': 'Haloperidol',  # SCZ\n",
    "#         'DB00734': 'Risperidone',  # AD\n",
    "#         'DB00472': 'Fluoxetine',  # AD\n",
    "#         'DB01104': 'Sertraline',  # AD\n",
    "#     }\n",
    "#     xticks = [np.argwhere(df_filtered.columns == k)[0][0] + .5 for k in to_label if k in df_filtered.columns]\n",
    "#     xticklabels = [v for k, v in to_label.items() if k in df_filtered.columns]\n",
    "#     ax.set_xticks(xticks)\n",
    "#     ax.set_xticklabels(xticklabels)\n",
    "\n",
    "#     # Save\n",
    "#     fname = f'Drug_Relevance_{group}_{disease}{get_fname_suffix(use_modules=use_modules)}.pdf'\n",
    "#     fig.savefig(os.path.join(PLOTS_FOLDER, fname), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOrilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Params\n",
    "# sort_param = '-log10(q)'\n",
    "# origin_files = [\n",
    "#     # Should be named <{Group}_{Disease}_{Cell Type}_prioritized_genes>_GOrilla.csv\n",
    "#     'UCLA_ASD_ASD_micro_prioritized_genes',\n",
    "# ]\n",
    "\n",
    "# # Plot\n",
    "# for fname in origin_files:\n",
    "#     # Enrichment done with rank-order GOrilla\n",
    "#     enrichment = pd.read_csv(os.path.join(RESULTS_FOLDER, f'{fname}_GOrilla.csv'))\n",
    "#     enrichment['-log10(p)'] = -np.log(enrichment['P-value'])\n",
    "#     enrichment['-log10(q)'] = -np.log(enrichment['FDR q-value'])\n",
    "\n",
    "#     # Filter to top\n",
    "#     enrichment = enrichment.sort_values(sort_param, ascending=False)\n",
    "#     enrichment = enrichment.iloc[:25]\n",
    "\n",
    "#     # Create figure\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(6, 8))\n",
    "#     sns.barplot(data=enrichment, x=sort_param, y='Description', ax=ax)\n",
    "#     ax.set_ylabel(None)\n",
    "#     ax.axvline(-np.log(.05), color='black')\n",
    "#     fig.savefig(os.path.join(PLOTS_FOLDER, f'Enrichment_GOrilla_{fname}.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metascape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the gene lists\n",
    "# Params\n",
    "percentages = (5, 10, 15)\n",
    "\n",
    "# Convert to gene lists\n",
    "for source, use_modules in product(data_sources, modules):\n",
    "    group, disease, _ = source\n",
    "    grn_fnames = get_grn_fnames(group, disease, use_ctl=use_ctl)[-1]\n",
    "\n",
    "    for i, fname in enumerate(grn_fnames):\n",
    "        cell_type = get_cell_type(fname)\n",
    "        result_fname = f'{group}_{disease}_{cell_type}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'\n",
    "        try: result = pd.read_csv(os.path.join(RESULTS_FOLDER, result_fname), index_col=0)\n",
    "        except: continue\n",
    "\n",
    "        # Sort and filter\n",
    "        result = result.sort_values('mean', ascending=False)\n",
    "        num_genes = result['mean'].shape[0]\n",
    "        df = pd.DataFrame({'_BACKGROUND': result.index.to_list()})\n",
    "        for percent in percentages:\n",
    "            num_genes_to_take = num_genes * percent // 100\n",
    "            df_concat = pd.DataFrame({f'{percent}p': result.index.to_list()[:num_genes_to_take]})\n",
    "            df = pd.concat((df, df_concat), axis=1)\n",
    "\n",
    "        # Save\n",
    "        fname = f'{group}_{disease}_{cell_type}_prioritized_genes_GO_genes{get_fname_suffix(use_modules=use_modules)}.csv'\n",
    "        df.to_csv(os.path.join(RESULTS_FOLDER, fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing the enrichments\n",
    "for source, use_modules in product(data_sources, modules):\n",
    "    group, disease, _ = source\n",
    "    grn_fnames = get_grn_fnames(group, disease, use_ctl=use_ctl)[-1]\n",
    "\n",
    "    for i, fname in enumerate(grn_fnames):\n",
    "        cell_type = get_cell_type(fname)\n",
    "        result_fname = f'{group}_{disease}_{cell_type}_prioritized_genes_GO_enrichment{get_fname_suffix(use_modules=use_modules)}.csv'\n",
    "        result_path = os.path.join(RESULTS_FOLDER, result_fname)\n",
    "        if not os.path.exists(result_path): continue\n",
    "        try: result = pd.read_csv(result_path, index_col=0)\n",
    "        except: continue\n",
    "\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
