{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd \"Compound GRN ENC Analysis/scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import sklearn.svm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "# Params\n",
    "DATA_FOLDER = os.path.join(os.path.abspath(''), '../../data')\n",
    "RESULTS_FOLDER = os.path.join(os.path.abspath(''), '../results')\n",
    "PLOTS_FOLDER = os.path.join(os.path.abspath(''), '../plots')\n",
    "\n",
    "# Style\n",
    "sns.set_theme(context='talk', style='white', palette='Accent')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "# matplotlib.rcParams['font.family'] = 'Helvetica'  # NOTE: Make sure to download Helvetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Consider weight scaling for disease and ctl individually (maybe?  Depends on methodology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert from Gerstein to project format\n",
    "# save_dir = os.path.join(DATA_FOLDER, 'merged_GRNs_v2', 'Subclass', 'ctrl')\n",
    "# read_dir = os.path.join(save_dir, 'original')\n",
    "# fnames = os.listdir(read_dir)\n",
    "# for fname in fnames:\n",
    "#     data = pd.read_csv(os.path.join(read_dir, fname), delimiter='\\t', low_memory=False)\n",
    "#     data = data.rename(columns={'TG': 'target', 'edgeWeight': 'importance'})[['TF', 'target', 'importance']]\n",
    "#     data = data.loc[data['importance'] > data['importance'].quantile(.9)]  # Filter to top 10%\n",
    "#     data.to_csv(os.path.join(save_dir, fname[:-7] + 'merged.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cohort : Disease : Delimiter\n",
    "CMC: SCZ : tsv\n",
    "UCLA_ASD: ASD : csv\n",
    "Urban_DLPFC: BPD, SCZ : tsv\n",
    "Subclass: ASD, BPD, SCZ : csv\n",
    "\"\"\"\n",
    "data_sources = (\n",
    "    ('CMC', 'SCZ', '\\t'),\n",
    "    ('UCLA_ASD', 'ASD', ','),\n",
    "    ('Urban_DLPFC', 'BPD', '\\t'),\n",
    "    ('Urban_DLPFC', 'SCZ', '\\t'),  # Removed for low sample size\n",
    "    ('Subclass', 'ASD', ','),  # No CTL\n",
    "    ('Subclass', 'BPD', ','),  # No CTL\n",
    "    ('Subclass', 'SCZ', ','),  # No CTL\n",
    ")\n",
    "modules = [None, 1, 2]\n",
    "group, disease, delimiter = data_sources[0]\n",
    "use_ctl = True\n",
    "use_modules = modules[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AD, BPD, and SCZ labels\n",
    "gene_dir = os.path.join(DATA_FOLDER, 'new_labels')\n",
    "gene_fnames = [fname for fname in os.listdir(gene_dir) if fname.endswith('.txt')]\n",
    "gene_lists = {'.'.join(fname.split('.')[:-1]): np.loadtxt(os.path.join(gene_dir, fname), dtype=str) for fname in gene_fnames}\n",
    "gene_lists['BPD'] = gene_lists.pop('BD')\n",
    "\n",
    "# Get ASD labels\n",
    "sfari = pd.read_csv(os.path.join(DATA_FOLDER, 'sfari/SFARI-Gene_genes_01-16-2024release_03-21-2024export.csv'))\n",
    "gene_score_threshold = -1\n",
    "sfari = sfari.loc[sfari['gene-score'] > gene_score_threshold]  # Threshold by score\n",
    "gene_lists['ASD'] = sfari['gene-symbol'].to_numpy()\n",
    "\n",
    "# Get module genes\n",
    "def get_module_genes(group, disease, ct):\n",
    "    gene_annotations = pd.read_csv(os.path.join(DATA_FOLDER, 'modules', get_modules_fname(use_modules=use_modules), f'{ct}_{group}_{disease}.txt'), index_col=False, delimiter=',')\n",
    "    positive_genes = gene_annotations.loc[gene_annotations['label']=='positive', 'gene'].to_list()\n",
    "    negative_genes = gene_annotations.loc[gene_annotations['label']=='negative', 'gene'].to_list()\n",
    "    return positive_genes, negative_genes\n",
    "\n",
    "# Get files for contrast\n",
    "def get_grn_fnames(group, disease):\n",
    "    # Calculate directories\n",
    "    base_dir = os.path.join(DATA_FOLDER, 'merged_GRNs_v2', group)\n",
    "    disease_folder = os.path.join(base_dir, disease)\n",
    "    if use_ctl: control_folder = os.path.join(base_dir, 'ctrl')\n",
    "    grn_fnames = np.sort(list(set(os.listdir(disease_folder)).intersection(set(os.listdir(control_folder)))))\n",
    "\n",
    "    # Return\n",
    "    ret = ()\n",
    "    ret += (base_dir, disease_folder)\n",
    "    if use_ctl: ret += (control_folder,)\n",
    "    ret += (grn_fnames,)\n",
    "    # base_dir, disease_folder, control_folder, grn_fnames\n",
    "    return ret\n",
    "if use_ctl: base_dir, disease_folder, control_folder, grn_fnames = get_grn_fnames(group, disease)\n",
    "else: base_dir, disease_folder, grn_fnames = get_grn_fnames(group, disease)\n",
    "\n",
    "# Get fname suffix\n",
    "def get_modules_fname(use_modules, **kwargs): return f'model{use_modules}' if use_modules is not None else ''\n",
    "def get_fname_suffix(**kwargs):\n",
    "    suffixes = [get_modules_fname(**kwargs)]\n",
    "    suffixes = [s for s in suffixes if len(s) > 0]\n",
    "    if len(suffixes) == 0: return ''\n",
    "    return f'_{\"_\".join(suffixes)}'\n",
    "\n",
    "# Get cell-type based on fname\n",
    "get_cell_type = lambda fname: '_'.join(fname.split('_')[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Classification\n",
    "        self.net = gnn.Sequential('x, edge_index, edge_weight', [\n",
    "            # Pure weighted GCN\n",
    "            (gnn.GCNConv(self.input_dim, self.embedding_dim), 'x, edge_index, edge_weight -> x'),\n",
    "            nn.BatchNorm1d(self.embedding_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout(.5),\n",
    "\n",
    "            (gnn.GCNConv(-1, self.embedding_dim // 2), 'x, edge_index, edge_weight -> x'),\n",
    "            nn.BatchNorm1d(self.embedding_dim // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.Dropout(.5),\n",
    "\n",
    "            (gnn.GCNConv(-1, 2), 'x, edge_index, edge_weight -> x'),\n",
    "        ])\n",
    "\n",
    "        # Embedding weights\n",
    "        self.embedding_net = nn.Sequential(\n",
    "            nn.Linear(2 * self.embedding_dim, 1),\n",
    "            # nn.Linear(self.embedding_dim, 1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        # return torch.matmul(self.net[0].lin.weight.T, self.net[3].lin.weight.T)\n",
    "        return self.net[0].lin.weight.T\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        return self.net(x, edge_index, edge_weight)\n",
    "\n",
    "    def predict_adjacency(self, idx=None):\n",
    "        \"\"\"Embedding loss function\"\"\"\n",
    "        # Get embeddings\n",
    "        embeddings = self.get_embeddings()\n",
    "\n",
    "        # Compare embeddings\n",
    "        predicted_adjacency_matrix = torch.zeros(embeddings.shape[0] if idx is None else len(idx), embeddings.shape[0])\n",
    "        for iter_num, i in enumerate(range(embeddings.shape[0]) if idx is None else idx):\n",
    "            x = torch.concat((embeddings[[i]].expand(embeddings.shape[0], -1), embeddings), dim=1)\n",
    "            predicted_adjacency_matrix[iter_num] = self.embedding_net(x).squeeze(dim=1)\n",
    "        predicted_adjacency_matrix.fill_diagonal_(0)  # Don't count self-comparisons\n",
    "\n",
    "        return predicted_adjacency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_to_tg(df, positive_genes, negative_genes=None):\n",
    "    \"\"\"Convert pandas dataframe to torch geometric dataset\"\"\"\n",
    "    df = df.rename(columns=dict(target='TG', importance='weight'))\n",
    "    unique = np.unique(list(df['TF'])+list(df['TG']))\n",
    "    x = np.eye(unique.shape[0])\n",
    "    node_dict = {k: v for v, k in enumerate(unique)}\n",
    "    node_dict_rev = {v: k for k, v in node_dict.items()}\n",
    "    from_edges = df['TF'].apply(lambda x: node_dict[x]).to_numpy()\n",
    "    to_edges = df['TG'].apply(lambda x: node_dict[x]).to_numpy()\n",
    "    edge_index = np.stack((from_edges, to_edges), axis=0)\n",
    "    edge_weight = df['weight'].to_numpy()\n",
    "\n",
    "    # Get y data\n",
    "    # -1 is unknown, 0 is no disease, 1 is disease\n",
    "    y = np.zeros(x.shape[0])-1  # Assign genes as unknown\n",
    "    y[[node_dict_rev[i] in positive_genes for i in range(x.shape[0])]] = 1  # Annotate positive genes\n",
    "    if negative_genes is not None:\n",
    "        y[[node_dict_rev[i] in negative_genes for i in range(x.shape[0])]] = 0  # Annotate negative genes\n",
    "    else:\n",
    "        y[np.argwhere(y!=1).flatten()] = 0  # Mark all others as negative\n",
    "\n",
    "    # Cast to tensors\n",
    "    x = torch.tensor(x).float()\n",
    "    edge_index = torch.tensor(edge_index).long()\n",
    "    edge_weight = torch.tensor(edge_weight).float()\n",
    "    if 'Cell Type' in df: edge_attr = torch.tensor(edge_attr).float()\n",
    "    y = torch.tensor(y).long()\n",
    "\n",
    "    # Torch data\n",
    "    data = torch_geometric.data.Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_weight=edge_weight,\n",
    "        y=y)\n",
    "\n",
    "    # Additional attributes\n",
    "    data.known_mask = y!=-1\n",
    "    data.adj_mat = torch.zeros(data.x.shape[0], data.x.shape[0])\n",
    "    for (tf, tg), w in zip(data.edge_index.T, data.edge_weight):\n",
    "        data.adj_mat[tf, tg] = w\n",
    "    data.node_dict = node_dict\n",
    "    data.disease = df['disease'].to_numpy()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astro - Fold 00\n",
      "epoch 0000 - dl: 1.579 - ccl: 0.863 - el: 1.801 - total: 1.579 _ val dl: 1.534 - val ccl: 0.852 - val el: 8.546 - val total: 1.534\n",
      "epoch 0020 - dl: 0.675 - ccl: 0.326 - el: 0.245 - total: 0.675 _ val dl: 0.584 - val ccl: 0.307 - val el: 0.768 - val total: 0.584\n",
      "epoch 0040 - dl: 0.642 - ccl: 0.314 - el: 1.531 - total: 0.642 _ val dl: 0.573 - val ccl: 0.300 - val el: 0.890 - val total: 0.573\n",
      "epoch 0060 - dl: 0.632 - ccl: 0.311 - el: 0.725 - total: 0.632 _ val dl: 0.559 - val ccl: 0.293 - val el: 0.799 - val total: 0.559\n",
      "epoch 0080 - dl: 0.617 - ccl: 0.304 - el: 0.592 - total: 0.617 _ val dl: 0.566 - val ccl: 0.297 - val el: 0.776 - val total: 0.566\n",
      "epoch 0100 - dl: 0.613 - ccl: 0.304 - el: 1.946 - total: 0.613 _ val dl: 0.568 - val ccl: 0.298 - val el: 0.760 - val total: 0.568\n",
      "auprc: 0.269 _ val auprc: 0.161 _ base auprc: 0.100\n",
      "\n",
      "astro - Fold 01\n",
      "epoch 0000 - dl: 1.061 - ccl: 0.565 - el: 1.071 - total: 1.061 _ val dl: 0.890 - val ccl: 0.438 - val el: 60.714 - val total: 0.890\n",
      "epoch 0020 - dl: 0.609 - ccl: 0.312 - el: 0.444 - total: 0.609 _ val dl: 0.543 - val ccl: 0.265 - val el: 1.782 - val total: 0.543\n",
      "epoch 0040 - dl: 0.542 - ccl: 0.289 - el: 1.270 - total: 0.542 _ val dl: 0.549 - val ccl: 0.283 - val el: 1.892 - val total: 0.549\n",
      "epoch 0060 - dl: 0.514 - ccl: 0.281 - el: 0.399 - total: 0.514 _ val dl: 0.587 - val ccl: 0.303 - val el: 1.878 - val total: 0.587\n",
      "epoch 0080 - dl: 0.492 - ccl: 0.270 - el: 1.213 - total: 0.492 _ val dl: 0.608 - val ccl: 0.311 - val el: 1.868 - val total: 0.608\n",
      "epoch 0100 - dl: 0.481 - ccl: 0.265 - el: 0.302 - total: 0.481 _ val dl: 0.624 - val ccl: 0.318 - val el: 1.859 - val total: 0.624\n",
      "auprc: 0.622 _ val auprc: 0.084 _ base auprc: 0.100\n",
      "\n",
      "astro - Fold 02\n",
      "epoch 0000 - dl: 1.407 - ccl: 0.695 - el: 3.047 - total: 1.407 _ val dl: 1.551 - val ccl: 0.793 - val el: 7.943 - val total: 1.551\n",
      "epoch 0020 - dl: 0.549 - ccl: 0.277 - el: 0.331 - total: 0.549 _ val dl: 0.964 - val ccl: 0.446 - val el: 0.592 - val total: 0.964\n",
      "epoch 0040 - dl: 0.503 - ccl: 0.260 - el: 0.470 - total: 0.503 _ val dl: 0.926 - val ccl: 0.454 - val el: 0.564 - val total: 0.926\n",
      "epoch 0060 - dl: 0.480 - ccl: 0.240 - el: 0.914 - total: 0.480 _ val dl: 0.873 - val ccl: 0.428 - val el: 0.816 - val total: 0.873\n",
      "epoch 0080 - dl: 0.472 - ccl: 0.239 - el: 3.929 - total: 0.472 _ val dl: 0.852 - val ccl: 0.423 - val el: 0.710 - val total: 0.852\n",
      "epoch 0100 - dl: 0.466 - ccl: 0.237 - el: 1.229 - total: 0.466 _ val dl: 0.848 - val ccl: 0.424 - val el: 0.652 - val total: 0.848\n",
      "auprc: 0.383 _ val auprc: 0.531 _ base auprc: 0.100\n",
      "\n",
      "astro - Fold 03\n",
      "epoch 0000 - dl: 4.385 - ccl: 2.305 - el: 0.746 - total: 4.385 _ val dl: 4.564 - val ccl: 2.497 - val el: 1.098 - val total: 4.564\n",
      "epoch 0020 - dl: 0.662 - ccl: 0.312 - el: 1.407 - total: 0.662 _ val dl: 0.814 - val ccl: 0.419 - val el: 1.137 - val total: 0.814\n",
      "epoch 0040 - dl: 0.644 - ccl: 0.310 - el: 2.709 - total: 0.644 _ val dl: 0.808 - val ccl: 0.404 - val el: 1.192 - val total: 0.808\n",
      "epoch 0060 - dl: 0.618 - ccl: 0.306 - el: 0.456 - total: 0.618 _ val dl: 0.809 - val ccl: 0.407 - val el: 1.151 - val total: 0.809\n",
      "epoch 0080 - dl: 0.606 - ccl: 0.305 - el: 1.408 - total: 0.606 _ val dl: 0.806 - val ccl: 0.406 - val el: 1.148 - val total: 0.806\n",
      "epoch 0100 - dl: 0.602 - ccl: 0.304 - el: 0.229 - total: 0.602 _ val dl: 0.804 - val ccl: 0.407 - val el: 1.158 - val total: 0.804\n",
      "auprc: 0.189 _ val auprc: 0.147 _ base auprc: 0.100\n",
      "\n",
      "astro - Fold 04\n",
      "epoch 0000 - dl: 1.590 - ccl: 0.824 - el: 8.525 - total: 1.590 _ val dl: 1.677 - val ccl: 0.888 - val el: 1.493 - val total: 1.677\n",
      "epoch 0020 - dl: 0.634 - ccl: 0.313 - el: 3.374 - total: 0.634 _ val dl: 0.641 - val ccl: 0.325 - val el: 4.338 - val total: 0.641\n",
      "epoch 0040 - dl: 0.621 - ccl: 0.307 - el: 3.576 - total: 0.621 _ val dl: 0.598 - val ccl: 0.291 - val el: 4.141 - val total: 0.598\n",
      "epoch 0060 - dl: 0.606 - ccl: 0.298 - el: 1.676 - total: 0.606 _ val dl: 0.604 - val ccl: 0.296 - val el: 3.875 - val total: 0.604\n",
      "epoch 0080 - dl: 0.597 - ccl: 0.296 - el: 1.063 - total: 0.597 _ val dl: 0.607 - val ccl: 0.298 - val el: 3.746 - val total: 0.607\n",
      "epoch 0100 - dl: 0.593 - ccl: 0.293 - el: 2.448 - total: 0.593 _ val dl: 0.609 - val ccl: 0.299 - val el: 3.685 - val total: 0.609\n",
      "auprc: 0.273 _ val auprc: 0.197 _ base auprc: 0.100\n",
      "\n",
      "\n",
      "endo - Fold 00\n",
      "epoch 0000 - dl: 2.054 - ccl: 1.061 - el: 2.375 - total: 2.054 _ val dl: 2.170 - val ccl: 1.089 - val el: 43.807 - val total: 2.170\n",
      "epoch 0020 - dl: 0.702 - ccl: 0.361 - el: 1.314 - total: 0.702 _ val dl: 0.623 - val ccl: 0.333 - val el: 0.874 - val total: 0.623\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39mnet[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlin\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43membedding_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Step\u001b[39;00m\n\u001b[1;32m     73\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Parameters\n",
    "epochs = 101\n",
    "epoch_cli = 20\n",
    "folds = 5\n",
    "embedding_loss_weight = 1e3\n",
    "\n",
    "# Run files\n",
    "stats = defaultdict(lambda: [])\n",
    "for fname in grn_fnames:\n",
    "    # Load graph\n",
    "    disease_graph = pd.read_csv(os.path.join(disease_folder, fname), index_col=False, delimiter=delimiter)\n",
    "    disease_graph['disease'] = True\n",
    "    if use_ctl:\n",
    "        control_graph = pd.read_csv(os.path.join(control_folder, fname), index_col=False, delimiter=delimiter)\n",
    "        control_graph['disease'] = False\n",
    "        combined_graph = pd.concat((disease_graph, control_graph), axis=0)\n",
    "    else:\n",
    "        combined_graph = disease_graph\n",
    "\n",
    "    # Procure gene lists\n",
    "    if not use_modules: positive_genes, negative_genes = gene_lists[disease], None\n",
    "    else: positive_genes, negative_genes = get_module_genes(group, disease, get_cell_type(fname))\n",
    "    graph = pd_to_tg(combined_graph, positive_genes, negative_genes=negative_genes)\n",
    "\n",
    "    # Run folds\n",
    "    folds_idx = torch.randperm(graph.x.shape[0]).split(int(np.ceil(graph.x.shape[0]/folds)))\n",
    "    for fold in range(folds):\n",
    "        # Get idx\n",
    "        val_fold = fold\n",
    "        train_folds = [i for i in range(folds) if i != val_fold]\n",
    "        graph.train_idx, graph.val_idx = torch.concat([folds_idx[i] for i in train_folds]), folds_idx[val_fold]\n",
    "        graph.train_mask = torch.zeros(graph.x.shape[0], dtype=torch.bool); graph.train_mask[graph.train_idx] = True\n",
    "        graph.val_mask = torch.zeros(graph.x.shape[0], dtype=torch.bool); graph.val_mask[graph.val_idx] = True\n",
    "        graph.train_mask *= graph.known_mask; graph.val_mask *= graph.known_mask\n",
    "        graph.train_idx = graph.train_mask.argwhere().flatten(); graph.val_idx = graph.val_mask.argwhere().flatten()\n",
    "\n",
    "        # Create model\n",
    "        model = GCN(graph.x.shape[1]).train()\n",
    "        # Calculate weights\n",
    "        # weight = torch.unique(graph.y[graph.train_mask], return_counts=True)[1]\n",
    "        # weight = weight.sum() / weight; weight = weight / weight.sum()\n",
    "        # Get helpers\n",
    "        classification_criterion = nn.CrossEntropyLoss()  # weight=weight\n",
    "        embedding_criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=.96)\n",
    "\n",
    "        # CLI\n",
    "        print(f'{get_cell_type(fname)} - Fold {fold:02d}')\n",
    "        for epoch in range(epochs):\n",
    "            # Run for disease and control\n",
    "            disease_z = model(graph.x, graph.edge_index[:, graph.disease], graph.edge_weight[graph.disease])\n",
    "            if use_ctl: control_z = model(graph.x, graph.edge_index[:, ~graph.disease], graph.edge_weight[~graph.disease])\n",
    "\n",
    "            # Get losses\n",
    "            idx = graph.train_idx\n",
    "            sub_idx = np.random.choice(graph.train_idx, len(graph.train_idx) // 10, replace=False)  # TODO: Add as a tunable hyperparameter\n",
    "            disease_classification_loss = classification_criterion(disease_z[idx], graph.y[idx])\n",
    "            if use_ctl: control_classification_loss = classification_criterion(control_z[idx], graph.y[idx])\n",
    "            embedding_loss = embedding_loss_weight * embedding_criterion(model.predict_adjacency(sub_idx), graph.adj_mat[sub_idx])  # Maybe replace adj_mat with disease or control?\n",
    "            loss = disease_classification_loss\n",
    "            if use_ctl: loss += control_classification_loss\n",
    "            model.net[0].lin.weight.requires_grad = False\n",
    "            loss.backward()\n",
    "            model.net[0].lin.weight.requires_grad = True\n",
    "            embedding_loss.backward()\n",
    "\n",
    "            # Step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "            # CLI\n",
    "            if epoch % epoch_cli == 0:\n",
    "                # Training\n",
    "                print(' - '.join([\n",
    "                    f'epoch {epoch:04d}',\n",
    "                    f'dl: {disease_classification_loss.detach().item():.3f}',\n",
    "                    f'ccl: {(control_classification_loss.detach().item() if use_ctl else 0):.3f}',\n",
    "                    f'el: {embedding_loss.detach().item():.3f}',\n",
    "                    f'total: {loss.detach().item():.3f}',\n",
    "                ]), end=' _ ')\n",
    "\n",
    "                # Validation\n",
    "                with torch.no_grad():\n",
    "                    idx = graph.val_idx\n",
    "                    disease_classification_loss = classification_criterion(disease_z[idx], graph.y[idx])\n",
    "                    if use_ctl: control_classification_loss = classification_criterion(control_z[idx], graph.y[idx])\n",
    "                    embedding_loss = embedding_loss_weight * embedding_criterion(model.predict_adjacency(idx), graph.adj_mat[idx])\n",
    "                    loss = disease_classification_loss\n",
    "                    if use_ctl: loss += control_classification_loss\n",
    "                print(' - '.join([\n",
    "                    f'val dl: {disease_classification_loss.detach().item():.3f}',\n",
    "                    f'val ccl: {(control_classification_loss.detach().item() if use_ctl else 0):.3f}',\n",
    "                    f'val el: {embedding_loss.detach().item():.3f}',\n",
    "                    f'val total: {loss.detach().item():.3f}',\n",
    "                ]))\n",
    "\n",
    "        # Finish training\n",
    "        model.eval()\n",
    "\n",
    "        # Record\n",
    "        stats['Cell Type'].append(get_cell_type(fname))\n",
    "        stats['Fold'].append(fold)\n",
    "\n",
    "        # Evaluation\n",
    "        disease_z = model(graph.x, graph.edge_index[:, graph.disease], graph.edge_weight[graph.disease]).detach()\n",
    "        if use_ctl: control_z = model(graph.x, graph.edge_index[:, ~graph.disease], graph.edge_weight[~graph.disease]).detach()\n",
    "        pred_prob = F.softmax(disease_z, dim=1)[:, 1]\n",
    "\n",
    "        # Training\n",
    "        auprc = sklearn.metrics.average_precision_score(graph.y[graph.train_mask], pred_prob[graph.train_mask])\n",
    "        # CLI\n",
    "        print(' - '.join([\n",
    "            f'auprc: {auprc:.3f}',\n",
    "        ]), end=' _ ')\n",
    "        # Record\n",
    "        stats['AUPRC'].append(auprc)\n",
    "\n",
    "        # Validation\n",
    "        auprc = sklearn.metrics.average_precision_score(graph.y[graph.val_mask], pred_prob[graph.val_mask])\n",
    "        # CLI\n",
    "        print(' - '.join([\n",
    "            f'val auprc: {auprc:.3f}',\n",
    "        ]), end=' _ ')\n",
    "        # Record\n",
    "        stats['Validation AUPRC'].append(auprc)\n",
    "\n",
    "        # Baselines\n",
    "        print(' - '.join([\n",
    "            f'base auprc: {graph.y[graph.known_mask].float().mean():.3f}',\n",
    "        ]))\n",
    "\n",
    "        # Save predictions\n",
    "        pred = F.softmax(disease_z, dim=1)[:, 1]\n",
    "        node_dict_rev = {v: k for k, v in graph.node_dict.items()}\n",
    "        node_labels = [node_dict_rev[i] for i in range(len(graph.node_dict))]\n",
    "        df = pd.DataFrame({'gene': node_labels, 'score': pred.numpy(), 'validation': graph.val_mask.numpy(), 'label': graph.y.numpy()})\n",
    "        df.to_csv(os.path.join(RESULTS_FOLDER, f'{group}_{disease}_{get_cell_type(fname)}_{fold}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'), index=False)\n",
    "\n",
    "        # Formatting\n",
    "        print()\n",
    "\n",
    "    # CLI\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results in cell-type files\n",
    "for fname in grn_fnames:\n",
    "    df = None\n",
    "    for fold in range(folds):\n",
    "        # Read file\n",
    "        df_join = pd.read_csv(os.path.join(RESULTS_FOLDER, f'{group}_{disease}_{get_cell_type(fname)}_{fold}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'))\n",
    "        df_join = df_join.set_index('gene')\n",
    "        df_join = df_join.rename(columns=lambda s: (s + f'_{fold}') if s not in ('gene', 'label') else s)\n",
    "\n",
    "        # Escape if first\n",
    "        if df is None: df = df_join; continue\n",
    "\n",
    "        # Concat\n",
    "        df_join = df_join.drop(columns='label')\n",
    "        df = df.join(df_join)\n",
    "\n",
    "    # Add mean and std\n",
    "    scores = df[[f'score_{fold}' for fold in range(folds)]]\n",
    "    df['mean'] = scores.mean(axis=1)\n",
    "    df['std'] = scores.std(axis=1)\n",
    "\n",
    "    # Order\n",
    "    df = df[['label', 'mean', 'std'] + [f'score_{fold}' for fold in range(folds)] + [f'validation_{fold}' for fold in range(folds)]]\n",
    "\n",
    "    # Save to file\n",
    "    df.to_csv(os.path.join(RESULTS_FOLDER, f'{group}_{disease}_{get_cell_type(fname)}_prioritized_genes{get_fname_suffix(use_modules=use_modules)}.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Save stats\n",
    "df = pd.DataFrame(stats)\n",
    "fname = os.path.join(RESULTS_FOLDER, f'{group}_{disease}_performance{get_fname_suffix(use_modules=use_modules)}.csv')\n",
    "df.to_csv(fname)  # Save stats\n",
    "# df = pd.read_csv(fname)  # Load stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
